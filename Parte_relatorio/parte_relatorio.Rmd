---
title: ""
geometry: textwidth=18cm,textheight=24cm
lang: pt-br
header-includes:
- \usepackage{setspace}
- \usepackage{indentfirst}
- \usepackage[utf8]{inputenc}
- \usepackage{mathptmx}
- \usepackage{enumerate}
- \usepackage{url} 
- \usepackage{lipsum}
- \usepackage{multicol}
output: pdf_document
fontsize: 10bp
---


\begin{titlepage}
\begin{center}
\thispagestyle{empty}
\begin{figure}[!htb]
\begin{center}
\begin{minipage}[b]{0.5\linewidth}
\begin{center}
\end{center}
\end{minipage}
\begin{minipage}[b]{0.7\linewidth}
\begin{center}
\vspace*{1cm}
 {\large \bf Universidade Estadual de Campinas\\[5pt]
Instituto de Matemática, Estatística e Computação Cientifica\\[3pt]
Departamento de Estatística}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\vspace*{\stretch{1}}
\begin{center}
\vspace*{5cm}
{\huge \bf Relatório \\[7pt]
Capítulo 5 - Comparação de dois grupos}
\end{center}
\vspace*{\stretch{1}}
\begin{center}
\vspace*{4cm}
{\Large \bf Hugo Calegari  RA:155738 \\
Leonardo Uchoa Pedreira RA:156231\break
}\\[3pt]
{\large \bf Professor: Verônica}\\[5pt]
\end{center}
\vspace*{\stretch{1}}
\centerline{\bf Campinas-SP, 29 de Junho de 2017}
\vspace*{\stretch{1}}
\end{center}
\end{titlepage}

\onehalfspacing
\newpage

#Introdução

O método de bootstrap faz parte de uma classe de métodos não-paramétricos de Monte Carlo que estimam a distribuição de uma população ou uma característica (parâmetro de interesse) por meio de reamostragem.

Métodos de reamostragem consideram as amostras (representativas) como uma população finita, a partir da qual reamostras são tomadas para estimar características e realizar inferências a respeito desta população. 

#Inferências baseadas em percentis pelo método de bootstrap

Ao se comparar dois grupos independentes, o método é aplicado como segue. Gera-se amostra por bootstrap para cada grupo:

- Para o j-ésimo grupo, obter amostras de bootstrap via amostragem aleatória com reposição ($n_{j}$) da seguinte amostra: $X_{1j}, \dots, X_{nj}$, para obter a seguinte: $X_{1j}^{*}, \dots, X_{nj}^{*}$;

Seja $\hat{\theta_{j}^{*}}$ a estimativa por bootstrap de $\theta_{j}$, tal que este parâmetro está associado com alguma característica de interesse. Seja, ainda, $D^{*} = \hat{\theta_{1}^{*}} - \hat{\theta_{2}^{*}}$. Ao se repetir este processo $B$ vezes (quantidade de réplicas) gera-se $D_{1}^{*}, \dots,  D_{B}^{*}$. Defina $l = \frac{\alpha}{2} B$ (determinação do limite inferior do intervalo de confiança), arredonde para o inteiro mais próximo, e $u = B - l$ (limite superior). Com isso, um intervalo de confiança aproximado de $1- \alpha$ para a diferença entre os verdadeiros parâmetros ($\theta_{1} - \theta_{2}$) é: $[D_{(l+1)}^{*}, D_{(u)}^{*}]$, em que $D_{(1)}^{*} \le \dots \le D_{(B)}^{*}$.


Uma vez que se quer testar a hipótese: $H_{0}: \theta_{1} = \theta_{2}$ que pode ser re-escrita de maneira equivalente como $H_{0}: \theta_{1} - \theta_{2} = 0$, pode-se utilizar as seguintes estruturas de acordo com o que segue. Para as estimativas de bootstrap de $\hat{\theta}^{*}_{1}$ e $\hat{\theta}^{*}_{2}$, seja $p^{*} = P(\hat{\theta}^{*}_{1} >  \hat{\theta}^{*}_{2})$ $\Leftrightarrow$ $p^{*} = P(\hat{\theta}^{*}_{1} -  \hat{\theta}^{*}_{2} > 0)$ $\Leftrightarrow$ $p^{*} = P(D^{*} > 0)$ (pode-se estimar esta probabilidade com o uso da proporção de $\hat{\theta}^{*}_{1} >  \hat{\theta}^{*}_{2}$ $\Leftrightarrow$ $D^{*} > 0$).

Sob a hipótese nula (igualdade dos verdadeiros parâmetros), assintoticamente (para n e B suficientemente grandes), $p^{*}$ tem distribuição uniforme. Assim, rejeita-se $H_{0}$ se $p^{*} \le \alpha/2$ ou se $p^{*} \ge 1 - \alpha/2$. Neste caso, a forma como foi estimado o valor de $p^{*}$ é: 

- Seja A  número de valores que são maiores que zero para todos (B) os valores das diferenças obtidos via bootstrap, isto é, entre os valores $D_{1}^{*}, \dots,  D_{B}^{*}$. Consequentemente, pode-se estabelecer: $p^{*} = A/B$.

Por conveniência é adotado o seguinte valor de $p$ estimado: $p_{m}^{*} = \min(p^{*}, 1-p^{*})$ (chamado de p-valor generalizado). Com isso, rejeita-se $H_{0}$ se $p_{m}^{*} \le \alpha/2$.


#Comparação de M-estimadores

Os M-estimadores que serão avaliados são os de locação. Quando se compara estes estimadores com dois grupos independentes, ainda se percebe que a inferência baseada nos percentis por meio do método de bootstrap é o melhor método. Um intervalo de confiança baseado na estimativa do erro padrão fornecerá boa probabilidade de cobertura quando o tamanho amostral é suficientemente grande, ou seja, para se ter razoável aproximação do erro padrão necessita-se de uma população para reamostragem (amostra) relativamente grande, para que características da variabilidade populacional seja captada. A boa cobertura também depende da suposição de que as diferenças etimadas são normalmente distribuídas (característica que pode ser encontrada para grandes amostra de diferenças), porém, é desconhecido o quão grande é o tamanho amostral deveria ser antes de que a aproximação seja considerada, particularmente quando a distribuição é assimétrica.

Quando os tamanhos amostrais são pequenos, todas as indicações são de que o método de percentil por bootstrap é o melhor, então este é recomendado em relação aos outros, como o método de bootstrap-t, até existir boa evidência de que algum outro método possa ser utilizado em seu lugar.

Nota-se que com o objetivo de comparar dois M-estimadores, de dois grupos independentes, precisa-se a cada replicação obter uma estimatica do parâmetro de interesse. Com isso, é utilizado algum algoritmo, como M.P.I. (médias ponderadas iteradas), M.P.V.I. (média de pseudovalores iterados) ou N.R. (Newton Raphson) .

#Comparação de média aparadas e medianas
Quando se compara médias aparadas e se tem pelo menos (nível de apara de) 20% dos dados desconsiderados para o seu cáculo, inferências baseadas no percentil pelo método de bootstrap é preferível quando comparado com o método de bootstrap-t (quando se utiliza a distribuição t de Student para determinar o valor crítico apropriado). A acurácia para o método de bootstrap-t é maior quando a quantidade de dados desconsiderados é pequena (pequeno nível de apara), mas há incertezas a respeito desse valor.

Para o caso no qual o objetivo é comparar as medianas, uma pequena mudança deve ser feita para quando se tem dados repetidos. Seja $M_{1}^{*}$ e $M_{2}^{*}$ medianas amostrais por bootstrap e $p^{*} = P(M_{1}^{*} > M_{2}^{*}) + 0,5P(M_{1}^{*} = M_{2}^{*})$. De maneira semelhante ao que foi determinado anteriormente para $p^{*}$, entre B amostras de bootstrap se A é o número de vezes em que $M_{1}^{*} > M_{2}^{*}$, e C é o número de vezes em que $M_{1}^{*} = M_{2}^{*}$, uma estimativa para $p^{*}$ é: $p^{*} = \frac{A}{B} + 0,5 \frac{C}{B}$. Assim, o p-valor é definido como $2 \min(p^{*}, 1 - p^{*})$.

Em termos de controle da probabilidade do erro do tipo 1, as indicações até o momento são de que o método de inferência baseada em percentil por bootstrap tem um bom desempenho independente de existir dados repetidos.

Com a dúvida levantada a respeito da precisão do método de bootstrap-t, de acordo com Keselman et al. (2004), este tem uma performance razoável quando se desconsidera um quantidade de 10% e 15% dos dados. 

Por exemplo, considere a situação na qual se tem duas amostra definidas como segue: $n_{1} = 40$ observações de uma amostra de distribuição normal padrão e $n_{2} = 20$ observações de uma amostra de distribuição lognormal deslocada, tal que a média aparada seja zero. Quando se testa a diferença entre os valores das médias, com nível de significância de $0,05$, e (nível de apara de) 10% da informação amostral retirada, observa-se que o nível de significância verdadeiro para o método bootstrap-t é $0,066$ comparado com $0.050$ para o método de percentil por bootstrap (ao usar $1000$ réplicas). Ao se reduzir o tamanho amostral $n_{1} = 20$ e $n_{2} = 10$ as estimativas do nível de significância verdadeiros são: $0.082$ e $0.074$ para os métodos de bootstrap-t e o de percentil por bootstrap. Agora, para o último tamanho amostral fixo, e uma quantidade de informação retirada de 20% (isto é, nível de apara de 20%), as estimativas dos níves são $0.081$ e $0.063$, para o método de bootstrap-t e o percentil via bootstrap. Isto nos indica que o controle que se tem da probabilidade do erro do tipo 1 ao utilizar o método de percentil por bootstrap é maior quando comparado com o método de bootstrap-t. Este controle é maior ainda à medida em que se desconsidera a porcentagem de informação (nível de apara).

A seguir será avaliado um exemplo no qual um intervalo de confiança será obtido a partir dos dados ao se desconsiderar o método de bootstrap e com o seu uso.

Considere o banco de dados no qual as informações obtidas foram de uma pesquisa com estudantes do curso introdutório de estatística (disponível no R, biblioteca "Lock5Data", dados "StudentSurvey"). Deseja-se saber se existe diferença entre o número médio de horas de exercícios para os sexos.

Ao se utilizar o método de bootstrap para calcular o erro padrão das diferenças dos valores médios de horas de exercícios para os sexos, foi obtido o seguinte intervalo de confiança: $[0,57 ; 2,96]$, ou seja, rejeita-se a hipótese de que o número médio de horas de exercícios por semana para homens e mulheres é igual. O mesmo resultado é obtido ao se utilizar a inferência pelo método de percentil via bootstrap. Neste caso, o intervalo de confiança obtido foi $[0.64 ; 2.94]$ ao se considerar um nível de significância de $\alpha = 0.05$. Note, além disso, que o primeiro intervalo possui muito mais informação à respeito da diferença entre os valores médios (intervalo maior) comparado com o segundo intervalo. No entanto, a precisão do segundo é maior do que o primeiro.


```{r, echo=FALSE}
library(Lock5Data)
data("StudentSurvey")

#with(StudentSurvey, summary(Exercise))
#with(StudentSurvey, summary(Gender))
#with(StudentSurvey, by(Exercise, Gender, mean, na.rm = TRUE))
newStudent = with(StudentSurvey, StudentSurvey[!is.na(Exercise), ])

```

```{r grafico_ic, fig.cap="Gráfico da densidade das diferenças entre os valores das médias do número de horas de exercícios por semana para os sexos, das reamostras. Nota-se que possui uma característica muito familiar com a distribuição normal, isto é, sua densidade em formato de sino.", fig.asp=0.57, echo=FALSE}
set.seed(12)
#library(ggplot2)
#library(xtable)
n = with(newStudent, by(Exercise, Gender, length))
B = 1000
female.samples = with(newStudent, matrix(sample(Exercise[Gender == "F"], size = n[1] *
B, replace = TRUE), B, n[1]))
male.samples = with(newStudent, matrix(sample(Exercise[Gender == "M"], size = n[2] *
B, replace = TRUE), B, n[2]))
female.means = apply(female.samples, 1, mean)
male.means = apply(male.samples, 1, mean)
boot.stat = male.means - female.means
#ggplot(data.frame(x = boot.stat), aes(x = x)) + geom_density()
plot(density(boot.stat), main = "Gráfico da densidade das diferenças entre as médias", ylab = "Densidade", xlab = "")

xbars = with(newStudent, by(Exercise, Gender, mean))
me = 2 * sd(boot.stat)
ic = (xbars[2] - xbars[1]) + c(-1, 1) * me

ic_boot.quantil = quantile(boot.stat, c(0.025, 0.975))
#round((xbars[2] - xbars[1]) + c(-1, 1) * me, 1)
```
